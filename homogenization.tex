\chapter{Homogenization and Justification}
First, let us define the adequate spaces for our problem. We consider the operator $\kappa: \mathbf{L}^2( \Omega) \longrightarrow \mathbf{H}^{-1/2}(\Gamma_D)$ being the trace operator, i.e., $\kappa (u) = u \vert_{\Gamma_D}$. With such a operator, it's possible to define the space of square integrable vector functions with homogeneous Dirichlet condition on $\Gamma_D$ by:
\begin{equation*}
    \mathbf{L}^2(\Omega, \Gamma_D) := \kappa^{-1}\big( \{ \mathbf{0}\}\big)
\end{equation*}
Note that the operator $\kappa$ defined is linear and continuous in the corresponding spaces, moreover, since $\{\mathbf{0}\}$ is a close subset, then $\mathbf{L}^2(\Omega, \Gamma_D)$ is a close subspace of $\mathbf{L}^2(\Omega)$.
\begin{rem}
In particular, $\mathbf{L}^2(\Omega, \Gamma_D)$ is separable, so that there exist a Hilbertian base associated.
\end{rem}
Given $\epsilon > 0$, let us fix $p \in (0,1)$ and consider $\mathbf{C}(p) \in \text{ lin}\big(Sym^{n\times n})$, the space of linear operator on the $n\times n$ symmetric matrices space, being uniformly elliptic and bounded elastic tensor. Also, denote by $\rho^{\epsilon}(\mathbf{x}) = \rho \big( \frac{\mathbf{x}}{\epsilon}\big)$ an uniformly bounded density and consider for fixed parameter $T > 0$ the following evolution PDE problem:
\begin{equation}
    \label{MainPDE}
    \left \{
    \begin{array}{cc}
        \rho^{\epsilon} \partial_{tt} u^{\epsilon} - \nabla\cdot \sigma^{\epsilon}(u^{\epsilon})= \mathbf{0} & \text{ in } (0,T) \times \Omega \\
        \sigma^{\epsilon}_{ij}(u^{\epsilon}) = C_{ijkl} \mathbf{e}_{kl}(u^{\epsilon}) & \text{ in } (0,T)\times \Omega \\
        u^{\epsilon} = \mathbf{0} & \text{ on } (0,T) \times \Gamma_D \\
        \sigma^{\epsilon}_{ij} n_j = \mathbf{F} & \text{ on } (0,T) \times \Gamma_N \\
        \partial_t u^{\epsilon} = u^{\epsilon} = \mathbf{0} & \text{ on } \{t=0\} \times \Omega
    \end{array}
    \right.
\end{equation}
\begin{prop}
Assuming $0 < \rho_0 \leq \rho\big( \frac{\mathbf{x}}{\epsilon} \big) < + \infty$ and $\mathbf{F} \in L^{\infty}(0,T;\mathbf{L}^2(\Omega,\Gamma_N))$ then there exist a unique solution $u^{\epsilon}$ to (\ref{MainPDE}) for each $\epsilon > 0$, such that
\begin{equation*}
    u \in \mathcal{C}^0(0,T;\mathbf{H}^1(\Omega,\Gamma_D)) \cap \mathcal{C}^1(0,T;\mathbf{L}^2(\Omega, \Gamma_D))
\end{equation*}
\end{prop}
The idea for the proof is the following:\\

Let us first note that problem (\ref{MainPDE}) can be rewritten in a variational form, satisfied in distributions over $(0,T)$ by: 
\begin{equation}
    \label{MainTimePDE}
    \begin{array}{cc}
        \text{Find } u^{\epsilon} \in \mathcal{C}^0 (0,T;\mathbf{H}^1(\Omega,\Gamma_D)) \cap \mathcal{C}^1(0,T;\mathbf{L}^2(\Omega,\Gamma_D)) & \text{ s.t. }\\
        \partial_{tt} (u^{\epsilon}(t),v)_{\Omega} + \mathcal{I}_{C}(u^{\epsilon}(t),v) = (\mathbf{F}(t),v)_{\Gamma_D}&  \forall v \in \mathbf{H}^1(\Omega,\Gamma_D) \\
        \partial_{t} u^{\epsilon}(0) = u^{\epsilon}(0) = \mathbf{0} & \\
    \end{array}
\end{equation}
being $\mathcal{I}_{C}(u,v) := \int_{\Omega} C_{ijkl}\mathbf{e}_{kl}(u^{\epsilon}(t)) \partial_{x_j} v_i$.
Now, let us prove the existence and uniqueness of solution for (\ref{MainTimePDE}).
\begin{enumerate}
    \item To do this, we'll consider approximated solutions to (\ref{MainTimePDE}). We define the subspace $V_m$ generated by the first $m \in \mathbb{N}$ eigenvectors $\{w_1, \dots, w_m \}$ being $(w_i)_{i \in \mathbb{N}} \subset \mathcal{C}^{\infty}(\Omega)$ a Hilbertian base of $\mathbf{L}^2(\Omega, \Gamma_D)$ were the regularity follows from bootstrap and by the Sobolev embedding.
    Then, we consider the problem in time, defined by:
    \begin{equation}
        \label{ApproxTimePDE}
        \begin{array}{cc}
            \text{Find } u^{\epsilon}_m: t \in (0,T) \longrightarrow u_m(t) \in V_m & \text{ s.t. } \\
            \partial_{tt}(u_m^{\epsilon}(t),v)_{\Omega} + \mathcal{I}_{C}(u^{\epsilon}_m(t),v) = (\mathbf{F}(t),v)_{\Gamma_N} & \forall v \in \mathbf{H}^1(\Omega,\Gamma_D) \\
            \partial_{t} u^{\epsilon}_m(0) = u^{\epsilon}_m(0) = \mathbf{0} & \\
        \end{array}
    \end{equation}
    \begin{rem}
    Note that the linear operator $b(t)(v) := (\mathbf{F}(t),v)_{\Gamma_N}$ is well-defined and moreover continuous on $\mathbf{H}^1(\Omega,\Gamma_D)$.
    This follows from the contruction of $\mathbf{L}^2(\Omega, \Gamma_D)$ since $\forall t \geq 0$, we have the bounds:
    \begin{align*}
        \vert b(t)(v) \vert & \leq \Vert \mathbf{F}(t) \Vert_{\mathbf{L}^2(\Gamma_N)} \Vert \gamma (v) \Vert_{\mathbf{L}^2(\Gamma_N)} \\
        & \leq \Vert \mathbf{F}\Vert_{\mathbf{L}^{\infty}(0,T;\mathbf{L}^2(\Gamma_N))} \Vert \gamma(v) \Vert_{\mathbf{L}^2(\partial \Omega)} \\
        & \leq \Vert \mathbf{F} \Vert_{\mathbf{L}^{\infty}(0,T;\mathbf{L}^2(\Gamma_N))} \Vert v \Vert_{\mathbf{L}^2(\Omega)}\\
        & = \Vert \mathbf{F}\Vert_{\mathbf{L}^{\infty}(0,T;\mathbf{L}^2(\Gamma_N))} \Vert v \Vert_{\mathbf{H}^1(\Omega, \Gamma_D)}
    \end{align*}
    \end{rem}
    Defining $u^{\epsilon}_m(t) = \sum_{i=1}^m \alpha_i^{\epsilon}(t) w_i$ with $\alpha_i^{\epsilon} (t) = (u^{\epsilon}_m(t),w_i)_{\Omega}$ it follows that the functions $\alpha_i^{\epsilon}$ are solutions to the ODE system of the form:
    \begin{equation}
        \label{AlphaODE}
        \begin{array}{cc}
            \partial_{tt} \alpha_i^{\epsilon}(t) + \lambda \alpha_i^{\epsilon}(t) = (\mathbf{F}(t),w_i)_{\Gamma_N}& \forall t \in (0,T) \\
            \partial_t \alpha_i^{\epsilon}(0) = \alpha_i^{\epsilon}(0) = 0 & 
        \end{array}
    \end{equation}
    being $(\lambda_i)_{i \geq 1}$ an increasing sequence of eigenvalues associated to the decomposition of the operator $\mathcal{I}_C(\cdot, \cdot)$.\\
    Let us note then, the solution to (\ref{AlphaODE}) is given in the form:
    \begin{equation}
        \label{AlphaODEsol}
        \alpha_i^{\epsilon} (t) = \frac{1}{\sqrt{\lambda_i}} \int\limits_0^t sin(\sqrt{\lambda_i} (t-s)) (\mathbf{F}(t),w_i)_{\Gamma_N} \, ds
    \end{equation}
    so that, defining the matrix 
    \begin{equation*}
        Q(\omega) =
        \begin{bmatrix}
        cos(\omega) & sin(\omega) \\
        -sin(\omega) & cos(\omega)
        \end{bmatrix}
    \end{equation*}
    we obtain the following relation for the solution and it's derivative in the form:
    \begin{equation}
        \label{MatrixODEsol}
        \begin{bmatrix}
        \sqrt{\lambda_i} \alpha_i^{\epsilon}(t) \\
        \partial_{t} \alpha_i^{\epsilon}(t) 
        \end{bmatrix}
        = \int \limits_0^t Q\big(\sqrt{\lambda_i}(t-s)\big)
        \begin{bmatrix}
        0 \\
        (\mathbf{F}(t),w_i)_{\Gamma_N}
        \end{bmatrix}
    \end{equation}
    
    \item Next, the sequence $(u^{\epsilon}_m)_{m \in \mathbb{N}}$ is of Cauchy type on the spaces $\mathcal{C}^0(0,T;\mathbf{H}^1(\Omega, \Gamma_D))$ and $\mathcal{C}^1(0,T; \mathbf{L}^2(\Omega,\Gamma_D))$.\\
    Let $m,p$ be two integers such that $p > m \geq 1$ then from (\ref{AlphaODEsol}) it follows that
    \begin{equation*}
        \mathcal{I}_C(u_p^{\epsilon}(t)- u_m^{\epsilon}(t),u_p^{\epsilon}(t)- u_m^{\epsilon}(t)) + \vert \partial_t (u_p^{\epsilon}(t)- u_m^{\epsilon}(t))_{\Omega} \vert^2 = \sum_{i=m+1}^p \big( \lambda_i \vert \alpha_i^{\epsilon}(t) \vert^2 + \vert \partial_t \alpha_i^{\epsilon}(t) \vert^2 \big) 
    \end{equation*}
    and since $Q(\omega)$ is an orthogonal matrix, from (\ref{MatrixODEsol}) it follows that
    \begin{equation}
        \label{AlphaBound}
        \big( \lambda_i \vert \alpha_i^{\epsilon}(t) \vert^2 + \vert \partial_t \alpha_i^{\epsilon}(t) \vert^2 \big)^{1/2} \leq \int \limits_0^t \vert (\mathbf{F}(t),w_i)_{\Gamma_N} \vert \, ds 
    \end{equation}
    so that, by using the Cauchy-Schwatz inequality, we obtain
    \begin{align*}
        \lambda_i \vert \alpha_i^{\epsilon}(t) \vert^2 + \vert \partial_t \alpha_i^{\epsilon}(t) \vert^2 &\leq 2 \big( \int_0^t \vert (\mathbf{F}(t),w_i)_{\Gamma_N} \vert \, ds \big)^2 \\
        & \leq  2 t \int_0^t \vert (\mathbf{F}(t),w_i)_{\Gamma_N} \vert^2 \, ds
    \end{align*}
    so we obtain finally the bound:
    \begin{equation*}
        \mathcal{I}_C \big(u_p^{\epsilon}(t) - u_m^{\epsilon}(t),u_p^{\epsilon}(t) - u_m^{\epsilon}(t) \big) + \vert \partial_t (u_p^{\epsilon}(t) - u_m^{\epsilon}(t)) \vert^2 \leq 2 \sum_{i=m+1}^p t \int_0^t (\mathbf{F}(s),w_i)_{\Gamma_N})^2 \, ds
    \end{equation*}
    Now, since $\mathbf{F} \in L^{\infty}(0,T;\mathbf{L}^2(\Omega, \Gamma_N))$ we obtain
    \begin{equation*}
        \underset{p,m \longrightarrow + \infty}{lim} \sum_{i=m+1}^p \big \{ T \int_0^T \vert (\mathbf{F}(s),w_i)_{\Gamma_N}\vert^2 \, ds = 0
    \end{equation*}
    and by using the uniform elliticity of the tensor $\mathbf{C}$, it follows that $(u_m^{\epsilon}(t))_{m \in \mathbb{N}}$ is a Cauchy sequence on the spaces $\mathcal{C}^0(0,T; \mathbf{H}^1(\Omega, \Gamma_D))$ and $\mathcal{C}^1(0,T; \mathbf{L}^2(\Omega, \Gamma_D))$.
    \item Since the above spaces are complete, there exist $u^{\epsilon}(t)$ limit as $m \longrightarrow +\infty$ of $u^{\epsilon}_m(t)$ belonging to the spaces $\mathcal{C}^0(0,T; \mathbf{H}^1(\Omega, \Gamma_D))$ and $\mathcal{C}^1(0,T; \mathbf{L}^2(\Omega, \Gamma_D))$.\\
    Let us see that $u^{\epsilon}$ effectively solves the problem (\ref{MainPDE}). To do this, let $m \geq 1$, and consider $\psi \in \mathcal{D}(0,T)$, since $u_m(t)$ solves (\ref{AlphaODE}) then it follows that:
    \begin{equation*}
        \int_0^T (u_m^{\epsilon}(t),v) \partial_{tt}\psi(t) + \int_0^T \mathcal{I}_C (u_m^{\epsilon}(t),v) \psi(t)  = \int_0^T (\mathbf{F}(t),v)_{\Gamma_N} \psi(t) 
    \end{equation*}
    so that, in the limit as $m \longrightarrow 0$, we have that $u^{\epsilon}(t)$ solves the problem
    \begin{equation*}
        \int_0^T (u^{\epsilon}(t),v)_{\Omega} \partial_{tt}\psi(t) + \int_0^T \mathcal{I}_C (u^{\epsilon}(t),v) \psi(t) = \int_0^T (\mathbf{F}(t),v)_{\Gamma_N}\psi(t) 
    \end{equation*}
    with $\partial_t u^{\epsilon}(0) = u^{\epsilon}(0) = 0$ and we obtain the results. Moreover, we have continuity with respect to boundary data, since from (\ref{AlphaBound}) the solution $u^{\epsilon}(t)$ in the limit satisfies the inequality 
    \begin{equation*}
        \big( \mathcal{I}_C(u^{\epsilon}(t), u^{\epsilon}(t))+ \vert \partial_t u^{\epsilon}(t) \vert^2 \big)^{1/2} \leq \int_0^T \vert \mathbf{F}(t) \Vert \, dt \leq \Vert \mathbf{F}\Vert_{L^{\infty}(0,T;\mathbf{L}^2(\Gamma_N)}
    \end{equation*}
    and by the uniform boundness of the tensor $C$, we obtain the bound
    \begin{equation*}
        \Vert u^{\epsilon} \Vert_{L^{\infty}(0,T;\mathbf{H}^1(\Omega, \Gamma_D))}  + \Vert \partial_t u^{\epsilon} \Vert_{L^{\infty}(0,T;\mathbf{L}^2(\Omega, \Gamma_N))} \lesssim \Vert \mathbf{F}\Vert_{L^{\infty}(0,T; \mathbf{L}^2(\Gamma_N))}
    \end{equation*}
    Note in particular that the above bound is independent of $\epsilon > 0$ since there is no dependency on the right-hand side of the inequality, so that, we obtain well-possedness for the multiscale elastic problem for each $\epsilon > 0$.
\end{enumerate}

%%%%%
%%%%% THE ABOVE ADDED 21/10/2018
%%%%%

Now, the idea is to obtain a reasonable result of time regularity for the solution of the multiscale elastodynamic model. The motivation comes from a result of \textit{Panasenko} who obtain such type of results in a general viscoelastic case.

In this case, the idea will be to use a bootstrap type method to obtain the time-regularity for the mixed boundary problem, using the bounds obtained from spectral theory.

\begin{prop}
Let $u^{\epsilon} \in \mathcal{C}^{0}(0,T; \mathbf{H}^1(\Omega, \Gamma_D))$ denote the unique solution of the mixed boundary multiscale problem and suppose also the regularity for the parameters and surface force given by $A^{jk} \in L^{\infty}(\mathbf{Y})$ and $\mathbf{F} \in \mathcal{C}^p(0,T; \mathbf{H}^{3/2}(\Omega))$, then for each $p \geq 1$ we have that:
\begin{equation*}
    u^{\epsilon}, \partial_t u^{\epsilon} \in \mathcal{C}^p(0,T; \mathbf{L}^2(\Omega, \Gamma_D))
\end{equation*}
\end{prop}
\begin{rem}
In particular, from the proof it's also possible to obtain that
\begin{equation*}
    u^{\epsilon}, \partial_t u^{\epsilon} \in \mathcal{C}^p(0,T; \mathbf{H}^1(\Omega, \Gamma_D))
\end{equation*}
\end{rem}
Now, let us develop the main idea of the proof:\\
\begin{itemize}
    \item Using the spectral theory for the existence of multiscale problem, we obtained a solution $u^{\epsilon}$ having regularity:
    \begin{equation*}
        u^{\epsilon} \in \mathcal{C}^0(0,T;\mathbf{H}^1(\Omega, \Gamma_D)) \cap \mathcal{C}^1(0,T;\mathbf{L}^2(\Omega, \Gamma_D))
    \end{equation*}
    so that we have the result valid for initial cases $p = 0, 1$.
    \item Let us take $\vert h \vert \ll 1$ such that $t+h \in (0,T)$ and define the difference with parameter $\epsilon > 0$ fixed as:
    \begin{equation*}
        u_h^{\epsilon}(t, \mathbf{x}, \frac{\mathbf{x}}{\epsilon}) := u^{\epsilon} (t+h, \mathbf{x}, \frac{\mathbf{x}}{\epsilon}) - u^{\epsilon}(t, \mathbf{x}, \frac{\mathbf{x}}{\epsilon})
    \end{equation*}
    Now, defining the diffference of surface force as
    \begin{equation*}
        \mathbf{F}_h(t):= \mathbf{F}(t+h) - \mathbf{F}(t)
    \end{equation*}
    we obtan the following problem satisfied for the function $u_h^{\epsilon}$ given by:
    \begin{equation*}
        (P_{\epsilon}) \left \{
        \begin{array}{cc}
            \rho^{\epsilon} \partial_{tt} u_h^{\epsilon} - \partial_{x_j} \big( A^{jk}(\frac{\mathbf{x}}{\epsilon}) \partial_{x_k} u_h^{\epsilon} \big) = \mathbf{0}  &  \text{ in } (0,T)\times \Omega \\
            A^{jk}(\frac{\mathbf{x}}{\epsilon}) \partial_{x_k} u_h^{\epsilon}n_j = \mathbf{F}_h & \text{ on } (0,T)\times \Gamma_N \\
            u^{\epsilon}_h = \mathbf{0} & \text{ on }(0,T)\times \Gamma_D
        \end{array}
        \right .
    \end{equation*}
    with initial condition at rest (i.e. $\partial_t u_h^{\epsilon} = u_h^{\epsilon} = \mathbf{0}$ on $\{t=0\} \times \Omega$).
    \item Using the assumption of regularity for the surface force $\mathbf{F}$, we recall from spectral theory the bound given by:
    \begin{equation*}
        \Vert u_h^{\epsilon} \Vert_{\mathbf{H}^1(\Omega, \Gamma_D)} + \Vert \partial_t u_h^{\epsilon}\Vert_{\mathbf{L}^2(\Omega, \Gamma_D)} \lesssim \int \limits_t^{t+h} \Vert \mathbf{F}(s) \Vert_{\mathbf{L}^2(\Gamma_N)} \, ds
    \end{equation*}
    so, from the continuity we obtain that as $h \rightarrow 0$, the terms 
    \begin{equation*}
        \Vert u_h^{\epsilon} \Vert_{\mathbf{H}^1(\Omega, \Gamma_D)}, \Vert \partial_t u_h^{\epsilon} \Vert_{\mathbf{L}^2 (\Omega, \Gamma_D)} \rightarrow 0
    \end{equation*}
    and then $u^{\epsilon} \in \mathcal{C}^2(0,T; \mathbf{L}^2(\Omega, \Gamma_D))$
    \item Now, let us observe that we can take a time derivative to the full problem $(P_{\epsilon}$, and obtain a similar multiscale problem. Applying again the spectral theory, is possible to obtain a solution $v_h^{\epsilon} = \partial_t u_h^{\epsilon}$, satisfying save bound as before. In such a way, it follows that:
    \begin{equation*}
        \Vert \partial_{tt} u_h^{\epsilon} \Vert_{\mathbf{H}^1(\Omega, \Gamma_D)} + \Vert \partial_t u_h^{\epsilon} \Vert_{\mathbf{L}^2 (\Omega, \Gamma_D)} \lesssim \int_t^{t+h} \Vert \partial_t \mathbf{F}_h(t) \Vert_{\mathbf{L}^2(\Gamma_N)}
    \end{equation*}
    so that, as $h \rightarrow 0$ we conclude the regularity
    \begin{equation*}
        \partial_t u_h^{\epsilon} \in \mathcal{C}^0(0,T;\mathbf{H}^1(\Omega, \Gamma_D)) \cap \mathcal{C}^1(0,T;\mathbf{L}^2(\Omega, \Gamma_D)) 
    \end{equation*}
    and then
    \begin{equation*}
        u_h^{\epsilon} \in \mathcal{C}^3(0,T; \mathbf{L}^2(\Omega, \Gamma_D))
    \end{equation*}
    and by a bootstrap type argument, the results follows for each $p \geq 1$.
\end{itemize}
\begin{rem}
Now, recall the proof of \textit{justification of the two-scale asymptotic solution}, we would need the hypothesis of continuity for the $\mathcal{O}(1)$ term, in the form:
\begin{equation*}
    v \in \mathcal{C}^2(0,T; \mathbf{H}^1(\Omega, \Gamma_D))
\end{equation*}
in such a way that the term $G_{tt}$ in bounded.
\end{rem}


%%%%%
%%%%% THE ABOVE ADDED 21/10/2018
%%%%%

\section{Homogenization in Fourier Domain}

The ideas are taken from the three main references:
\begin{enumerate}
    \item The influence of mesoscale porosity on cortical bone anisotropy. Investigations via asymptotic homogenization. \textbf{W. Parnell \& Q. Grimal}.
    \item Generalized Models and Non-classical Approaches in Complex Materials I. Chapter 10. \textbf{F. Sabina, S. Dumont, I. Sevostianov}.
    \item Homogenisation: Averaging Processes in Periodic Media Mathematical Problems in the Mechanics of Composite Materials. \textbf{N. S. Bakhvalov, G. Panasenko}.
\end{enumerate}

The two-scale homogenization method enables us to obtain effective equation goberning the overall macroscopic mechanical behavior incorporating the periodic microstructure. In this section, we describe the heuristic procedure to obtain the governing equation then used in the numerical simulations.

With the region $\Omega \subset \mathbb{R}^d$ and boundary $\partial \Omega = \Gamma_D \dot\cup \Gamma_N$, the general model to study using engineering notation is described for fixed time $t \in \mathbb{R}_+$ by the problem :
\begin{equation}
    \label{VectorPDE-Elasticity}
    \left \{
    \begin{array}{cc}
        \rho^{\epsilon}u^{\epsilon}(\mathbf{x}) \partial_{tt} u^{\epsilon}(\mathbf{x},t) - div \, \sigma(u^{\epsilon}(\mathbf{x},t)) = \mathbf{0} & \text{ in } \Omega \\
        u^{\epsilon}(\mathbf{x}, t) = \mathbf{0} & \text{ on } \Gamma_D\\
        \sigma(u(\mathbf{x},t)) \cdot n = \mathbf{F}(\mathbf{x},t) & \text{ on } \Gamma_N
    \end{array}
    \right .
\end{equation}
where we associate also a initial condition in the form $u(\mathbf{x}, t) = 0 \text{ in } \Omega \times \{0\}$. For the constitutive law, we consider a generalized \textit{Hooke's} law, i.e.
\begin{equation}
    \label{ConstituteEq}
    \sigma^{\epsilon}(u^{\epsilon}(\mathbf{x}, t)) = \mathbf{C}(\mathbf{x}) : \mathbf{e}(u(\mathbf{x},t)) 
\end{equation}
where $\mathbf{C} = (C_{ijkl})$, and $\mathbf{e}(u(\mathbf{x},t)) = \mathbf{e}_{kl}(u(\mathbf{x},t))$ denotes the fourth rank and second rank tensors of elastic and strain respectively. In particular, the strain relationship in given in the form
\begin{equation}
    \label{StrainEq}
    \mathbf{e}_{kl} (u(\mathbf{x},t)) = \frac{1}{2}\big( \partial_{x_l} u_k(\mathbf{x},t) + \partial_{x_k} u_l (\mathbf{x},t) \big)
\end{equation}
We take also, additional conditions:
\begin{enumerate}
    \item We take $\mathbf{x}$ as the global coordinate. Also, interoduce a fast (or local) variable $\mathbf{y}$ in the form $y = \epsilon^{-1}\mathbf{x}$ where the parameter $\epsilon$ represents the a fine periodicity of the cell structure.
    \item The stress tensor $C_{ijkl}$ satisfies that $\mathbf{C}^{\epsilon} (\mathbf{x}) = \mathbf{C}(\mathbf{x}/\epsilon)$ being Y-periodic (related to the fast variable microstructure length).
\end{enumerate}

Following the standard literature, the time-domain evolution problem is transformed via \textit{Fourier} transform, and the applied an asymptotic approximated solution.

Let us take Fourier transform to the problem, in such a way that we consider particular solutions for a frequency $\omega \in \mathbb{R}$ in the form:
\begin{equation}
    \label{FreqAnsatz}
    u^{\epsilon}(\mathbf{x},t) = \hat{u}^{\epsilon}(\mathbf{x},\omega) e^{i \omega t}
\end{equation}
In this case, the problem defined in \ref{VectorPDE-Elasticity}, \ref{ConstituteEq}, \ref{StrainEq} with initial conditions becomes then:
\begin{equation}
    \label{VectorPDE-Freq}
    \left \{
    \begin{array}{cc}
        -\rho^{\epsilon} (\mathbf{x}) \omega^2 \hat{u}^{\epsilon}(\mathbf{x}) - \text{div }\sigma (\hat{u}^{\epsilon}(\mathbf{x})) = \hat{F}(\mathbf{x})  & \text{ in }  \Omega \\
        \sigma^{\epsilon} (\hat{u}(\mathbf{x})) = \mathbf{C}^{\epsilon}(\mathbf{x}): \mathbf{e} (\hat{u}^{\epsilon}(\mathbf{x})) & \text{ in } \Omega  \\
        \hat{u}(\mathbf{x}) = \mathbf{0} & \text{ on } \Gamma_D\\
        \sigma (\hat{u}(\mathbf{x}))\cdot n = \hat{\mathbf{F}}(\mathbf{x}) & \text{ on } \Gamma_N \\
    \end{array}
    \right .
\end{equation}
where we have omitted the frequency dependency on the solution $\hat{u}^{\epsilon}$ for easy of exposure and used $\Hat{F}(\mathbf{x})$ as the Fourier transform at frequency $\omega$, i.e. we've used the equality $F(\mathbf{x}) = \Hat{F}(\mathbf{x})e^{i \omega t}$.

\subsection{Two-Scale Asymptotic Homogenization}
We'll find an asymptotic solution for \ref{VectorPDE-Freq} at a fixed frequency $\omega$ in the form:
\begin{equation*}
    \label{AsymptoticExpansion}
    \hat{u}(\mathbf{x},\epsilon) = \sum_{a=0}^{\infty} \epsilon^a \hat{u}^{(a)}(\mathbf{x},\mathbf{y}) 
\end{equation*}
where the vector functions $\hat{u}^{(a)}$ are Y-periodic for each $a >0$. 
In particular, we assume throughout enough regularity
\begin{equation*}
    \hat{u}^{(a)}(\mathbf{x},\mathbf{y}) \in \mathbf{H}^1\big(\Omega; \, \mathbf{H}^1_{\#}(\mathbf{Y})\big)
\end{equation*}
Since we have an explicit relation between the slow and fast variable, we consider natural expressions of strain rate dependent on the variable. Let us define for $\Phi \in \mathcal{C}^{\infty}(\Omega \times \mathbf{Y})$ the expressions related to the shear rate:
\begin{align*}
    \mathbf{e}_{kl,\alpha} (\Phi(\alpha)) = \frac{1}{2}(\partial_{\alpha_l} \Phi_k (\alpha) + \partial_{x_k} \Phi (\alpha)) \quad \forall \alpha \in \{\mathbf{x}, \mathbf{y}\}
\end{align*}
With the above definition we can define a strain tensor $\mathbf{e}(\cdot)$ which satisfies the relation at components $k,l$ the relation:
\begin{equation}
    \label{Multiscale-Strain}
    \mathbf{e}_{kl} ( \hat{u}^{(a)}(\mathbf{x}, \frac{\mathbf{x}}{\epsilon})) = \mathbf{e}_{kl,x}( \hat{u}^{(a)} (\mathbf{x},\mathbf{y})) + \epsilon^{-1} \mathbf{e}_{kl,y} (\hat{u}^{(a)}(\mathbf{x},\mathbf{y})) \quad (10.19)
\end{equation}
%%%%%%%%%%%%
The main idea in the following is a separation of scales with so-called homogenized coefficients, approximating the overall macroscopic (effective) behavior by applying the asymptotic approximation solution:
\begin{equation*}
    -\rho^{\epsilon}(\mathbf{x}) \omega^2 \hat{u}(\mathbf{x}, \epsilon) + P^{(\epsilon)}\hat{u}(\mathbf{x},\epsilon) \sim \mathcal{O}(\epsilon) 
\end{equation*}
where the operator $P^{(\epsilon)}$ is defined by:
\begin{equation}
    \label{P-Operator}
    P^{(\epsilon)}\hat{u}(\mathbf{x},\epsilon) \sim - div \, (\mathbf{C}(\mathbf{x}): \epsilon(\hat{u}(\mathbf{x},\epsilon)))
\end{equation}

To handle derivatives from \ref{P-Operator}, let us define the operator 
\begin{equation*}
    L_{\alpha \beta} (\cdot) = - \partial_{\alpha_j} \big( C_{ijkl} (\mathbf{y}) \mathbf{e}_{kl, \beta}(\cdot) \big), \quad \alpha, \beta \in \{ \mathbf{x},\mathbf{y} \}
\end{equation*}
And recall that, by the chain rule we have $\forall \Phi$ with the enough regularity stated before:
\begin{equation*}
    \partial_{x_j} (\Phi (\mathbf{x}, \frac{\mathbf{x}}{\epsilon})) = \big \{ \partial_{x_j} \Phi (\mathbf{x}, \mathbf{y}) + \frac{1}{\epsilon} \partial_{y_j} \Phi(\mathbf{x},\mathbf{y}) \big \}_{\mathbf{y}= \epsilon^{-1}\mathbf{x}}
\end{equation*}

Now, using \ref{AsymptoticExpansion},\ref{Multiscale-Strain} we would like to regroup in powers of $\epsilon$. To do this, note that by \ref{P-Operator} it follows:
\begin{equation*}
    P^{(\epsilon)}(\hat{u}(\mathbf{x},\epsilon)) = A + B + C + \mathcal{O}(\epsilon^3)
\end{equation*}
where 
\begin{equation*}
    \begin{array}{cc}
        A &= P^{(\epsilon)}(\hat{u}^{(0)}(\mathbf{x},\xi)) \\
        B &= \epsilon P^{(\epsilon)}(\hat{u}^{(1)}(\mathbf{x},\epsilon)) \\
        C &= \epsilon^2 P^{(\epsilon)}(\hat{u}^{(2)}(\mathbf{x},\epsilon)) \\
    \end{array}
\end{equation*}
Expanding every term, then using \ref{Multiscale-Strain} we have that:
\begin{align*}
    A &= - \partial_{x_j} \big( C_{ijkl}\mathbf{e}(\hat{u}^{(0)}) \big) \\
    &=- \partial_{x_j} \big( C_{ijkl} \mathbf{e}_{kl,x} (\hat{u}^{(0)}) + \frac{1}{\epsilon}C_{ijkl}\mathbf{e}_{kl,y}(\hat{u}^{(0)} \big)\\
    &= - L_{xx}\hat{u}^{(0)} - \frac{1}{\epsilon} L_{yx}\hat{u}^{(0)} - \frac{1}{\epsilon} L_{xy}\hat{u}^{(0)} - \frac{1}{\epsilon^2}L_{yy}\hat{u}^{(0)}
\end{align*}
Similarly, for the other terms we have that:
\begin{align*}
    B &= -\epsilon L_{xx} \hat{u}^{(1)} - L_{yx}\hat{u}^{(1)} - L_{xy} \hat{u}^{(1)} - \frac{1}{\epsilon} L_{yy}\hat{u}^{(1)} \\
    C &= -\epsilon^2 L_{xx} \hat{u}^{(2)} - \epsilon L_{yx}\hat{u}^{(2)} - \epsilon L_{xy} \hat{u}^{(2)} - L_{yy}\hat{u}^{(2)} 
\end{align*}
So, we obtain that for powers of $\epsilon$ the necessary conditions:
\begin{equation}
    \label{Epsilon-Separation}
    \begin{array}{cc}
        \epsilon^{-2} \longrightarrow & L_{yy} \hat{u}^{(0)} = \mathbf{0} \\
        \epsilon^{-1} \longrightarrow & L_{xy}\hat{u}^{(0)} + L_{yx}\hat{u}^{(0)} + L_{yy}\hat{u}^{(1)} = \mathbf{0} \\
        \epsilon^{0} \longrightarrow & L_{xx}\hat{u}^{(0)} + L_{xy} \hat{u}^{(1)} + L_{yx}\hat{u}^{(1)} + L_{yy}^{(2)} + \rho(\mathbf{x}) \hat{u}^{(0)} = \mathbf{0}
    \end{array}
\end{equation}

Let us consider the asymptotic expansion \ref{AsymptoticExpansion} as an approximation for the exact solution of the original problem \ref{VectorPDE-Freq} where their boundary conditions had been replaced to the behavior at $\mathcal{O}(1)$.
\begin{equation*}
    \left \{
    \begin{array}{cc}   
        \hat{u}^{(0)}(\mathbf{x},\mathbf{y}) = \mathbf{0} & \forall \mathbf{x} \in \Gamma_D\\
        \big(\mathbf{C}(\mathbf{y}): \epsilon (\hat{u}^{(0)}(\mathbf{x}, \mathbf{y}) \big) \cdot n = \hat{\mathbf{F}}(\mathbf{x}) & \forall (\mathbf{x},\mathbf{y}) \in \Gamma_N \times \partial \mathbf{Y}
    \end{array}
    \right .
\end{equation*}
and the remaining terms for each $a \in \mathbb{N}$ in the expansion are assigned by
\begin{equation*}
    \begin{array}{cc}
        \hat{u}^{(a)}(\mathbf{x},\mathbf{y}) = \mathbf{0} & \forall (\mathbf{x}, \mathbf{y}) \in \Gamma_D\times \partial \mathbf{Y} \\
        \big( \mathbf{C}(\mathbf{y}): \epsilon(\hat{u}^{(a)}(\mathbf{x},\mathbf{y}) \big) \cdot n = 0 & \forall  (\mathbf{x}, \mathbf{y}) \in \Gamma_D\times \partial \mathbf{Y} 
    \end{array}
\end{equation*}

Let us recall a classical results for elliptic problems. It relates the existence for problems in \ref{Epsilon-Separation} by some compatibility conditions.
\begin{lem}
\label{ExistenceLemma}
Let $f(\cdot)$ be a square integrable function over $\mathbf{Y}$. Consider the problem:
\begin{equation*}
    L_{yy} \Phi(\mathbf{y}) = f(\mathbf{y}) \text{ in } \mathbf{Y}
\end{equation*}
where $\Phi$ is $\mathbf{Y}$-periodic function. Then it holds:
\begin{enumerate}
    \item There exist a $\mathbf{Y}$-periodic solution $\Phi$ iff $\langle f \rangle = 0$
    \item If a $Y$-periodic solution $\Phi$ exists, then it's unique up to a constant vector $\mathbf{c} \in \mathbb{R}^d$.
\end{enumerate}
\end{lem}

\begin{rem}
We are considering the notation
\begin{equation*}
    \langle f \rangle := \frac{1}{\vert Y \vert} \int_{\mathbf{Y}} f(\mathbf{y}) \, d\mathbf{y}
\end{equation*}
where $\vert Y \vert$ denotes the measure of the set $\mathbf{Y}$.
\end{rem}

\subsection{Contribution at order $\epsilon^{-2}$}
Recall that, the problem \ref{VectorPDE-Freq} with their boundary conditions states:
\begin{equation}
    \label{Order-2VectorPDE}
    \left \{
    \begin{array}{cc}
        L_{yy} \hat{u}^{(0)}( \mathbf{x},\mathbf{y}) = \mathbf{0} & \text{ in } \Omega \times \mathbf{Y}\\
        \hat{u}^{(0)} (\mathbf{x},\mathbf{y}) = \mathbf{0} & \text{ in } \Gamma_D \times \mathbf{Y} \\
        \big( \mathbf{C}(\mathbf{y}) :\epsilon(\hat{u}^{(0)}(\mathbf{x},\mathbf{y}) \big) \cdot n = \hat{\mathbf{F}}(\mathbf{x}) & \text{ in } \Gamma_N \times \mathbf{Y} \\
    \end{array}
    \right .
\end{equation}
By the Lemma (\ref{ExistenceLemma}) we have $\hat{u}(\mathbf{x},\mathbf{y})$ is solution of \ref{Order-2VectorPDE} iff it's constant w.r.t the $\mathbf{y}$-variable. It implies that:
\begin{equation}
    \label{IndepencyofY}
    \hat{u}^{(0)}(\mathbf{x},\mathbf{y}) = \hat{v}(\mathbf{x})
\end{equation}
i.e. being independent with respect to the microstructure $\mathbf{Y}$. Moreover, the boundary conditions applied are the ones in the macroscopic variable:
\begin{equation*}
    \left \{
    \begin{array}{cc}
        \hat{v}^{(0)}(\mathbf{x}) = \mathbf{0} & \text{ on } \Gamma_D\\
        \big(\mathbf{C}(\mathbf{y}):\epsilon(\hat{v}(\mathbf{x})) \big) \cdot n = \hat{\mathbf{F}}(\mathbf{x}, & \text{ on } \Gamma_N \times \mathbf{Y}
    \end{array}
    \right .
\end{equation*}

\subsection{Contributions at order $\epsilon^{-1}$}
Since by \ref{IndepencyofY} we have $\hat{u}^{(0)}(\mathbf{x},\mathbf{y}) = \hat{v}(\mathbf{x})$ then we can deduce by definition that:
\begin{equation*}
    L_{xy} \hat{v}(\mathbf{x}) = 0
\end{equation*}
So, the problem formulation in \ref{Epsilon-Separation} is reduced to
\begin{equation*}
    \label{Order-1VectorPDE}
    \left \{
    \begin{array}{cc}
        L_{yy} \hat{u}^{(1)}(\mathbf{x},\mathbf{y}) = - L_{yx} \hat{v}(\mathbf{x}) & \text{ in } \Omega \times \mathbf{Y} \\
        \hat{u}^{(1)}(\mathbf{x},\mathbf{y}) = \mathbf{0} & \text{ on } \Gamma_D \times \mathbf{Y} \\
        \big( \mathbf{C}(\mathbf{y}) : \epsilon( \hat{u}^{(1)}(\mathbf{x},\mathbf{y})) \big) \cdot n = \mathbf{0} & \text{ on } \Gamma_N \times \mathbf{Y}
    \end{array}
    \right .
\end{equation*}
Now, using the Lemma \ref{ExistenceLemma} on \ref{Order-1VectorPDE} taking into account \ref{IndepencyofY}, the $Y$-periodicity of $\mathbf{C}(\mathbf{y})$ and the diverge theorem, it follows:
\begin{equation*}
    \big\langle - L_{yx} \hat{u}^{(0)}(\mathbf{x}, \cdot) \big\rangle = \mathbf{0}
\end{equation*}
then the existence of solution for problem \ref{Order-1VectorPDE} it's satisfied.

Now, by separation of variables and the second condition of lemma (\ref{ExistenceLemma}), a general solution to the system of equations \ref{Order-1VectorPDE} can be given by:
\begin{equation}
    \label{Order-1Ansatz}
    \hat{u}^{(1)}(\mathbf{x},\mathbf{y}) = \mathbf{N}^{rs}(\mathbf{y}) \epsilon_{rs,x}(\hat{v}(\mathbf{x})) + \hat{w}(\mathbf{x}) \quad (10.42)
\end{equation}
where $\hat{\mathbf{N}}^{rs} \in \mathbf{H}^1_{\#}(\mathbf{Y})$ it's called the local vector function and $\hat{\mathbf{w}}$ infinitely differentiable vector function.

Then replacing \ref{IndepencyofY}, \ref{Order-1Ansatz} into \ref{Order-1VectorPDE} to obtain the so called cell problems. Explicitly, note that applying the above we obtain the following:
\begin{align*}
    &\,L_{yy} \big( \hat{\mathbf{N}}^{rs} (\mathbf{y}) \mathbf{e}_{rs,x} (\hat{v}(\mathbf{x})) \big) + L_{yx}(\hat{v}(\mathbf{x}) ) = \mathbf{0} \\
    \implies& -\partial_{y_j} \big( C_{ijkl}\mathbf{e}_{kl,y}(\hat{\mathbf{N}}^{rs}(\mathbf{y}) ) \mathbf{e}_{rs,x}(\hat{v}(\mathbf{x})) = \partial_{y_j} \big( C_{ijrs}\mathbf{e}_{rs,x}(\hat{v}(\mathbf{x})) \big) \\
    \implies& - \partial_{y_j} \big( C_{ijkl} \mathbf{e}_{kl,y} (\hat{\mathbf{N}}^{rs}(\mathbf{y})) \big) = \partial_{y_j} (C_{ijrs})
\end{align*}
and applying lemma \ref{ExistenceLemma}, it follows that $\hat{\mathbf{N}}^{rs}$ is $Y$-periodic, where we add the boundary conditions taken from \ref{Order-1VectorPDE} obtaining:
\begin{equation*}
    \left \{
    \begin{array}{cc}
        \hat{\mathbf{N}}^{rs}(\mathbf{y}, \omega) = \mathbf{0} & \text{ in } \mathbf{Y} \times \mathbb{R} \\
        \big( \mathbf{C}(\mathbf{y}) : \epsilon(\hat{\mathbf{N}}^{rs}(\mathbf{y}, \omega)) \big) \cdot n = \mathbf{0} & \text{ on } \mathbf{Y}\times \mathbb{R}  \\
        \hat{\mathbf{N}}^{rs} (\mathbf{y},0) = \mathbf{0} &  \text{ in } \mathbf{Y}
    \end{array}
    \right.
\end{equation*}

where the above by construction using the ansatz \ref{Order-1Ansatz} define a solution to the PDE system \ref{Order-1VectorPDE}.


\subsection{Contribution to the order $\epsilon^{0}$}
In this case, problem \ref{VectorPDE-Freq} after regrouping the terms at $\mathcal{O}(1)$ becomes:
\begin{equation}
    \label{Order-0VectorPDE}
    \begin{array}{cc}
        L_{yy} \hat{u}^{(2)} =-\rho^{\epsilon}(\mathbf{x})\omega^2 \hat{v}(\mathbf{x}) - \tilde{P}(\hat{u}^{(1)},\hat{u}^{(2)}) (\mathbf{x},\mathbf{y}) & \text{ in } \Omega \times \mathbf{Y} \\
        \hat{u}^{(2)}(\mathbf{x},\mathbf{y}) = \mathbf{0} & \text{ on } \Gamma_D \times \mathbf{Y} \\
        \big( \mathbf{C}(\mathbf{y}) : \epsilon(\hat{u}^{(2)}(\mathbf{x},\mathbf{y}) \big) \cdot n = \mathbf{0} & \text{ on } \Gamma_N\times \mathbf{Y}
    \end{array}
\end{equation}
where we have denoted 
\begin{equation*}
    \tilde{P}(\hat{u}^{(0)}, \hat{u}^{(1)}) (\mathbf{x},\mathbf{y}) :=  L_{xx} \hat{u}^{(0)} + L_{xy} \hat{u}^{(1)} + L_{yx} \hat{u}^{(1)}
\end{equation*}
then by Lemma \ref{ExistenceLemma}, we have existence of one $Y$-periodic solution of \ref{Order-0VectorPDE} iff 
\begin{equation}
    \label{Order-0ExistenceCond}
    \big \langle \rho(\mathbf{y}) \omega^2 \hat{v}(\mathbf{x}) - L_{xx} \hat{u}^{(1)} (\mathbf{x},\mathbf{y}) - L_{xy} \hat{u}^{(1)}(\mathbf{x},\mathbf{y}) - L_{yx}\hat{u}^{(1)}(\mathbf{x},\mathbf{y}) \big \rangle = \mathbf{0}
\end{equation}
From \ref{Order-0ExistenceCond} the homogenized equation is obtained, which can be deduced explicitly in the form:
\begin{align*}
    &-\langle \rho(\mathbf{y}) \rangle \omega^2 \hat{v}(\mathbf{x}) + \langle L_{xx} \hat{u}^{(0)}(\mathbf{x},\mathbf{y}) +L_{xy} \hat{u}^{(1)}(\mathbf{x},\mathbf{y}) \rangle = \mathbf{0} \\
    \Leftrightarrow & -\langle \rho(\mathbf{y}) \rangle \omega^2 \hat{v}(\mathbf{x}) + \langle L_{xx}\hat{u}^{(0)}(\mathbf{x}, \mathbf{y}) + L_{xy}\big( \hat{\mathbf{N}}^{rs}(\mathbf{y})\epsilon_{rs,x}(\hat{v}(\mathbf{x})) + \hat{w}(\mathbf{x})\big) = \mathbf{0} \\
    \Leftrightarrow & -\langle \rho\rangle \omega^2 \hat{v}_i(\mathbf{x}) - \partial_{x_j}\big \langle \big(\hat{C}_{ijrs}^{hom}(\mathbf{N}^{rs})\big) \epsilon_{rs,x}(\hat{v}(\mathbf{x})) \big \rangle  = \mathbf{0} \quad \forall i \in \{1,\dots, d\}\\
    \Leftrightarrow& -\langle \rho \rangle \omega^2 \hat{v}_i(\mathbf{x}) - \hat{C}_{ijkl}^{hom} \partial_{x_j} \mathbf{e}_{rs,x} (\hat{v}(\mathbf{x})) = \mathbf{0} \quad \forall i \in \{1,\dots,d\}
\end{align*}
where we have denoted $\hat{C}_{ijrs}^{hom}$ the so-called homogenized elastic coefficients defined by 
\begin{equation*}
    \hat{C}_{ijrs}^{hom} = \big \langle C_{ijrs}(\mathbf{y}) + C_{ijkl}\mathbf{e}_{kl,y}\big(\hat{\mathbf{N}}^{rs}(\mathbf{y})\big) \big \rangle 
\end{equation*}
With the above definition and the homogenized equation obtained from (\ref{Order-0VectorPDE}) we obtain the effective behavior of the system defined by:
\begin{equation}
    \label{HomogenizedPDE}
    \left \{
    \begin{array}{cc}
        - \langle \rho \rangle \omega^2 \hat{v}(\mathbf{x}) (\mathbf{x}) - \nabla \cdot \sigma^{hom} (\hat{v}(\mathbf{x}) ) = \mathbf{0} & \text{ in } \Omega \\
        \sigma^{hom}_{ij}(\hat{v}(\mathbf{x})) = C^{hom}_{ijkl}\mathbf{e}_{kl,x}(\hat{v}(\mathbf{x})) & \text{ in } \Omega \\
        \hat{v}(\mathbf{x}) = \mathbf{0} & \text{ on } \Gamma_D \\
        \sigma^{hom}(\hat{v}(\mathbf{x})) \cdot n = \mathbf{F}(\mathbf{x}) & \text{ on } \Gamma_N
    \end{array}
    \right .
\end{equation}
In particular, the PDE problem \ref{HomogenizedPDE} is well-posed, and moreover the mechanical behavior maintains the linear elasticity property from the material.

Let us note in particular that the homogenized elastic operator define a bilinear form on $\mathbf{H}^1(\Omega, \Gamma_D)$ by:
\begin{equation*}
    a(u,v) := \int \limits_{\Omega} \sigma^{hom}_{ij}(u(\mathbf{x}) \partial_{x_j} v_i \, dx \quad u,v \in \mathbf{H}^1(\Omega, \Gamma_D)
\end{equation*}
moreover, since the homogenized coefficients are bounded and uniformly elliptic we can then apply the classical theorem of spectral decomposition of the operator:
\begin{prop}
Let $V \subset H$ Hilbert spaces, such that $V$ is dense and continuously embedded in $H$. Suppose the canonical injection from $V$ on $H$ is compact, and the bilinear form $a(\cdot, \cdot)$ is symmetric, V-elliptic. Then there exist an increasing sequence which tend to $+ \infty$ of eigenvalues
\begin{equation*}
    0 < \lambda_1 \leq \lambda_2  \leq \dots \lambda_m \leq \cdots 
\end{equation*}
and a hilbertian orthonormal base of $H$ given by eigenvector $w_m$ such that:
\begin{equation*}
    \forall v \in V, \quad a(w_,, v) = \lambda_m (w_m, v), \quad \forall m = 1, 2, \dots
\end{equation*}
\end{prop}





\section{Justification of the homogenization}
Having obtained the homogenized model, in this section it's developed the justification procedure of convergence of solutions in the space $\mathbf{H}^1(\Omega, \Gamma_D)$. To handle easily the derivatives, we rewrite our problem formulation to a canonical form described below \footnote{The choice of a cannonical formulation for the mixed boundary elastodynamic model is based on the straighforward usage of space derivatives and the estimation necessary to assure the justification of the asymptotic solution, in the sense that the two-scale approximate solution $u^{\epsilon}(\mathbf{x},t)$ converge to the real (experimental solution) $u(\mathbf{x},t)$ in some space with enough regularity.}.
Over the bounded smooth domain $\Omega \subset \mathbb{R}^d$ we consider the multiscale evolution problem:
\begin{equation}
    \label{MainMultiPDE}
    \left \{
    \begin{array}{cc}
        \mathcal{L}_{\epsilon}(u^{\epsilon}) = \rho\big( \frac{\mathbf{x}}{\epsilon} \big) \partial_{tt} u^{\epsilon} - \partial_{x_h} \big( A^{hk}\big( \frac{\mathbf{x}}{\epsilon} \big) \partial_{x_k} u^{\epsilon} \big)  = \mathbf{0} & \text{ in } (0,T)\times \Omega  \\
        \sigma^{\epsilon}(u^{\epsilon}) n := A^{hk}\big( \frac{\mathbf{x}}{\epsilon} \big) \partial_{x_k} u^{\epsilon} n_k  = \mathbf{F}(t,\mathbf{x}) & \text{ on } (0,T) \times \Gamma_N \\
        u^{\epsilon} =  \mathbf{0} & \text{ on } (0,T) \times \Gamma_D \\
        \partial_t u^{\epsilon} = u^{\epsilon} = \mathbf{0} & \text{ on } \{ t=0 \} \times \Omega 
    \end{array}
    \right.
\end{equation}
where we suppose $\Gamma_D \dot \cup \Gamma_N = \partial \Omega$ and assume enough regularity for the boundaries (at least Lipschitz). It is also assumed that the coefficients matrices $A^{hk}$ satisfy conditions of uniformly ellipticity and boundness for all $t \in (0,T)$. \\
Consider also the \textit{homogeneous} mixed problem for each $t \in (0,T)$ in the form:
\begin{equation}
    \label{HomMultiPDE}
    \left \{
    \begin{array}{ccc}
        \mathcal{L}_0 (u^0) = \rho^0 \partial_{tt} u^0 - \partial_{x_h}\big( A^{hk}_{hom} \partial_{x_k} u^0 \big) = \mathbf{0} & \text{ in } (0,T)\times \Omega \\
        \sigma^0(u^0)n := A^{hk}_{hom} \partial_{x_k}u^0 n = \mathbf{F} & \text{ on } (0,T) \times \Gamma_N \\
        u^0 = \mathbf{0} & \text{ on } (0,T) \times \Gamma_D \\
        \partial_t u^0 = u^0 = \mathbf{0} & \text{ on } \{ t=0 \} \times \Omega
    \end{array}
    \right .
\end{equation}
where the matrices $A^{hk}_{hom}$ are defined by the formulas:
\begin{equation}
    \label{HomCoeffs}
    A^{pq}_{hom} = \int \limits_{\mathbf{Y}} A^{pq}(\mathbf{y}) + A^{pj} (\mathbf{y}) \partial_{y_j} \mathbf{N}^q (\mathbf{y}) \, d\mathbf{y}
\end{equation}
where the matrices $\mathbf{N}^q(\mathbf{y})$ are solutions of the following boundary value problem:
\begin{equation}
    \label{CellProblems}
    \left \{
    \begin{array}{ccc}
        \partial_{y_k} \big( A^{kj}(\mathbf{y}) \partial_{y_j} \mathbf{N}^q \big) = -\partial_{y_k} \big( A^{kq}(\mathbf{y}) \big) & \text{ in } \mathbf{Y} \\
        \mathbf{N}^q(\mathbf{y}) \text{ being 1-periodic} in \mathbf{y} & \int_{\mathbf{Y}}  \mathbf{N}^q (\mathbf{y}) \, d\mathbf{y} = \mathbf{0}
    \end{array}
    \right .
\end{equation}
where $\mathbf{Y} = (0,1)^N$ and $N \in \mathbf{N}^*$ denotes the dimension, usually $2$ or $3$.\\

\begin{rem}
 Let us observe that from (\ref{CellProblems}) in its variational form and by the coercivity and boundness condition over the coefficients $A^{kj}(\mathbf{y})$, if follows that formula (\ref{HomCoeffs}) inherit also the continuity and boundness condition. It follows then that the homogenized problem (\ref{HomMultiPDE}) is of elastic type, and moreover we can apply the same proof as in the case of REF PROP 2.2 obtaining then by bootstraping method the result:
 \begin{equation*}
     u^0, \, \partial_{t} u^0 \in \mathcal{C}^p (0,T; \mathbf{H}^1(\Omega, \Gamma_D))
 \end{equation*}
\end{rem}


We seek an approximate solution to problem (\ref{MainMultiPDE}) in the form:
\begin{equation}
    \label{Asymptotic}
    \tilde{u}(t,\mathbf{x}) = u^0 (t,\mathbf{x}) + \epsilon \varphi(\mathbf{x}) \mathbf{N}^{s} \big(t,\frac{\mathbf{x}}{\epsilon}) \partial_{x_s} u^0(t,x)
\end{equation}
where $u^0$ is the solution to problem (\ref{HomMultiPDE}), the $\mathbf{N}^{s} (\mathbf{y})$ solutions to (\ref{CellProblems}) and moreover the function $\varphi(\mathbf{x})$ denotes the truncation function satisfying the conditions 
\begin{enumerate}
    \item $\varphi \in \mathcal{C}^{\infty}(\Omega)$ with $\vert \nabla \varphi\vert \lesssim \epsilon^{-1}$,
    \item $\varphi = 0$ in $\Gamma_D$ and $\varphi = 1$ outside an $\epsilon$-neighborhood of $\Gamma_D$.
\end{enumerate}
Such type of functions exists, in particular, we can consider the function $\varphi(\mathbf{x}) := w(\epsilon^{-1} \rho(\mathbf{x},\Gamma_D))$ being

\begin{equation*}
    w(t) = 
    \left \{
    \begin{array}{cc}
        t & \text{ if } 0 \leq t \leq 1 \\
        1 & \text{ if } t > 1
    \end{array}
    \right .
\end{equation*}

\begin{rem}
The truncation function $\varphi$ enters in the expression of $\tilde{u}$ since the matrices $\mathbf{N}^s \big(\frac{\mathbf{x}}{\epsilon}\big)$ are in general not defined in a neighborhood of $\Gamma_D$ (the other boundaries $\Gamma_N$ are associated with \textit{Neumann} type boundary conditions).
\end{rem}

Now, we enunciate the main result, with a sketch of proof in the next section
\begin{theo}
Assuming that $\mathbf{F} \in L^{\infty}(0,T;\mathbf{L}^{2}(\Gamma_N))$ and also $\mathbf{N}^q \in L^{\infty}(0,T; \mathbf{H}^1(\Omega))$ for each $q \in \{1,\dots, N\}$. Then the solutions $u^{\epsilon}$ and $u^0$ of problems (\ref{MainMultiPDE}) and (\ref{HomMultiPDE}) respectively, satisfy the following inequality
\begin{equation*}
    \label{MainInequality}
    \Vert u^{\epsilon} - u^0 - \epsilon \varphi \mathbf{N}^s \big(\frac{\mathbf{x}}{\epsilon} \big) \partial_{x_s} u^0 \Vert_{L^{\infty}(0,T; \mathbf{H}^1(\Omega, \Gamma_D))} \lesssim \epsilon^{1/2} \Vert \mathbf{F}\Vert_{L^{\infty}(0,T; \mathbf{L}^{2}(\Gamma_N)}
\end{equation*}
\end{theo}

\section{Ideas for the Proof}
Let us consider the following expression:
\begin{equation*}
    \alpha^{is}(\mathbf{y}) := A^{is}_{hom} - A^{is}(\mathbf{y}) - A^{ij}(\mathbf{y}) \partial_{y_j} \mathbf{N}^s(\mathbf{y}), \quad i,s \in \{1,\dots, N\}
\end{equation*}
\begin{lem}
The matrices $\alpha^{is}(\mathbf{y})$ satisfy the conditions:
\begin{equation}
    \label{AlphaCondition}
    \begin{array}{cc}
         \int \limits_{\mathbf{Y}} \alpha^{is}(\mathbf{y}) \, d\mathbf{y} = \mathbf{0} & \forall i,s \in \{1,\dots, N\} \\
         \partial_{y_i} \alpha^{is}(\mathbf{y}) = 0 & \text{ in }\mathbf{Y}, \forall s \in \{1,\dots, N\}
    \end{array}
\end{equation}
\end{lem}

Now, lets us see the main sketch of proof:\\

Le us apply the operator $\mathcal{L}_{\epsilon}$ to a vector valued function $u^{\epsilon}-\tilde{u}$, where $\tilde{u}$ is defined by (\ref{Asymptotic}), then:
\begin{align*}
    \mathcal{L}_{\epsilon} (u^{\epsilon}-\tilde{u}) &= \rho^{\epsilon} \partial_{tt} (u^{\epsilon}-\tilde{u}) - \partial_{x_h} \big( A^{hk}\partial_{x_k} u^{\epsilon} \big) + \partial_{x_h} \big( A^{hk}\partial_{x_k} (u^0 + \epsilon \varphi \mathbf{N}^s \partial_{x_s}u^0 )\big) \\
    & \overset{(*)}{=} - \epsilon \varphi \rho^{\epsilon} \partial_{tt} \big( \mathbf{N}^s \partial_{x_s}u^0 \big) - \partial_{x_h} \big( \big[ A^{hk}_{hom} - A^{hk} - \epsilon A^{hj}\partial_{x_j} (\varphi \mathbf{N}^k \big] \partial_{x_k} u^0\big) \\
    &\, + \epsilon \partial_{x_h} \big( \varphi A^{hk} \mathbf{N}^s \partial_{x_k x_h} u^0 \\
    & \overset{(**)}{=} - \epsilon \varphi \rho^{\epsilon} \partial_{tt} \big( \mathbf{N}^s \partial_{x_s}u^0 \big) - \partial_{x_h} \big( (1-\varphi) \big[ A^{hk}_{hom} - A^{hk} \big] \partial_{x_k} u^0 \big)  \\
    &\, - \partial_{x_h} \big( \varphi \big[ A^{hk}_{hom} - A^{hk} - \epsilon A^{hj} \partial_{x_j} \mathbf{N}^k \big] \partial_{x_k} u^0 \big) \\
    &\, + \partial_{x_h} \big( \big[ \epsilon A^{hj} \partial_{x_j} \varphi \mathbf{N}^k \big] \partial_{x_k} u^0 \big) + \epsilon \partial_{x_h} \big( \varphi A^{hk} \mathbf{N}^s \partial_{x_k x_s} u^0 \big) 
\end{align*}
where in $(*)$ we've reordered and relabeled the terms and in $(**)$ we've added a new term.
Taking into account the equation in (\ref{CellProblems}) for the $\mathbf{N}^s$ we obtain:
\begin{align*}
    \mathcal{L}_{\epsilon} (u^{\epsilon} - \tilde{u}) & = - \epsilon \varphi \rho^{\epsilon} \partial_{tt} \big( \mathbf{N}^s \partial_{x_s} u^0 \big) - \partial_{x_h} \big( (1-\varphi) \big[ A^{hk}_{hom} - A^{hk} \big] \partial_{x_k} u^0 \big) \\
    & \, - \big[ A^{hk}_{hom} - A^{hk} - \epsilon A^{hj} \partial_{x_j} \mathbf{N}^k - \epsilon \partial_{x_s} \big( A^{sh}\mathbf{N}^k \big) \big] \varphi \partial_{x_k x_h} u^0 \\
    &\, - \partial_{x_h} \varphi \alpha^{hk} \partial_{x_k} u^0 + \epsilon \partial_{x_h} \big( \partial_{x_j} \varphi A^{hj} \mathbf{N}^k \partial_{x_k} u^0 \big) + \epsilon \partial_{x_h} \varphi A^{hk} \mathbf{N}^s \partial_{x_k x_s} u^0 \\
    & \, + \epsilon \varphi A^{hk} \mathbf{N}^s \partial_{x_k x_h x_s} u^0
\end{align*}
Let us define the matrices $\mathbf{N}^{hk}(\mathbf{y})$ as weak solutions of the following boundary value problem
\begin{equation}
    \label{SecondCellProblem}
    \left \{
    \begin{array}{cc}
        \partial_{y_j} \big( A^{jl}\partial_{y_l} \mathbf{N}^{hk}\big) = -\partial_{y_s} \big( A^{sh} \mathbf{N}^k\big) - A^{hj}\partial_{y_j} \mathbf{N}^k - A^{hk} + A^{hk}_{hom} & \text{ in } \mathbf{Y}\\
        \mathbf{N}^{hk}(\mathbf{y}) \text{ being $\mathbf{Y}$-periodic}
    \end{array}
    \right .
\end{equation}
So, using (\ref{SecondCellProblem}) we can obtain:
\begin{align*}
    \mathcal{L}_{\epsilon} (u^{\epsilon} -\tilde{u}) & = - \epsilon \varphi \rho^{\epsilon} \partial_{tt} \big( \mathbf{N}^s \partial_{x_s} u^0\big) - \partial_{x_h} \big( (1-\varphi) \big[ A^{hk}_{hom} - A^{hk} \big] \partial_{x_k} u^0 \big) \\
    & \, - \epsilon \partial_{x_j} \big[ \varphi A^{jl} \partial_{y_l} \mathbf{N}^{hk} \partial_{x_k x_h} u^0 \big] + \epsilon \partial_{x_j} \varphi A^{jl} \partial_{y_l} \partial_{x_k x_h} u^0 \\
    &\, + \epsilon \varphi A^{jl} \partial_{y_l} \mathbf{N}^{hk} \partial_{x_j x_k x_h} u^0 - \partial_{x_h}\varphi \alpha^{hk} \partial_{x_k} u^0 \\
    & \, + \epsilon \partial_{x_h} \big[ \partial_{x_j} \varphi A^{hj} \mathbf{N}^{k} \partial_{x_k} u^0 \big] + \epsilon \partial_{x_h} \varphi A^{hk} \mathbf{N}^s \partial_{x_k x_s} u^0 \\
    & \, + \epsilon \varphi A^{hk} \mathbf{N}^s \partial_{x_k x_h x_s} u^0 
\end{align*}

Thus, we have:
\begin{equation}
    \mathcal{L}_{\epsilon} (u^{\epsilon}-\tilde{u}) = G_{tt} + \partial_{x_h} G_h^1 + \partial_{x_j} G_j^2 + G_1^0 + G_2^0 + G_3^0
\end{equation}
where each term is defined by:
\begin{equation}
    \label{Variables}
    \begin{array}{cc}
        G_{tt}= & -\epsilon \varphi \rho^{\epsilon} \partial_{tt} \big( \mathbf{N}^s \partial_{x_s} u^0 \big) \\
        G_h^1= &-(1-\varphi) \big[ A^{hk}_{hom} - A^{hk}\big] \partial_{x_k} u^0 + \epsilon \partial_{x_j}\varphi A^{hj} \mathbf{N}^k \partial_{x_k} u^0 \\
        G_j^2 = & -\epsilon \varphi A^{jl}\partial_{y_l} \mathbf{N}^{hk} \partial_{x_k x_h} u^0 \\
        G_1^0 = & \epsilon \partial_{x_j} \varphi A^{jl} \partial_{y_l} \mathbf{N}^{hk} \partial_{x_k x_h} u^0 + \epsilon \partial_{x_h} \varphi A^{hk} \mathbf{N}^s \partial_{x_k x_s} u^0 \\
        G_2^0 = & \epsilon \varphi A^{jl} \partial_{y_l} \mathbf{N}^{hk} \partial_{x_j x_k x_h} u^0 + \epsilon \varphi A^{hk} \mathbf{N}^s \partial_{x_k x_h x_s} u^0 \\
        G_3^0 = & - \partial_{x_h} \varphi \alpha^{hk} \partial_{x_k} u^0
    \end{array}
\end{equation}
\begin{rem}
Let us note that in $\Gamma_D$ we have by construction $\varphi = 0$ so that by the (\ref{Asymptotic}) expansion, it follows that $u^{\epsilon}\vert_{\Gamma_D} = u^0 \vert_{\Gamma_D}$.
\end{rem}
Let us now, obtain the \textit{Neumann} expression for the difference $u^{\epsilon} - \tilde{u}$. We have:
\begin{align*}
    \sigma_{\epsilon} (u^{\epsilon} - \tilde{u}) =& A^{ij} \partial_{x_j} (u^{\epsilon}) n_i - A^{ij} \partial_{x_j} \big( u^0 + \epsilon \varphi \mathbf{N}^s \partial_{x_s}u^0\big) n_i \\
    &= (1-\varphi) A^{ij} \partial_{x_j} (u^{\epsilon})n_i - (1-\varphi) A^{ij}_{hom} \partial_{x_j} (u^0) n_i + (1-\varphi) \big( A^{ij}_{hom} - A^{ij} \big) \partial_{x_j} (u^0)n_i \\
    &\, - \varphi \big( A^{ij} + \epsilon A^{il} \partial_{x_l} \mathbf{N}^j \big) n_i \partial_{x_j}(u^0) - \epsilon A^{ij} \partial_{x_j}\varphi \mathbf{N}^s \partial_{x_s}(u^0) n_i \\
    &\, - \epsilon A^{ij} \varphi \mathbf{N}^s \partial_{x_s x_j} u^0 n_i 
\end{align*}
It follows then from (\ref{Variables}) that:
\begin{equation}
    \label{NeumannCond}
    \sigma_{\epsilon} (u^{\epsilon}-\tilde{u}) = (1-\varphi) A^{ij} \partial_{x_j}(u^{\epsilon}) n_i - (1-\varphi) A^{ij}_{hom} \partial_{x_j}(u^0)n_i - G_h^1 n_h - G_j^2 n_j \text{ on } \partial \Omega
\end{equation}
Let us define by $\Omega \setminus \Omega_1(\epsilon)$ the $\epsilon$-neighborhood of $\Gamma_D$ such that $\varphi = 0$. Due to the boundary conditions for $u^0, u^{\epsilon}$ and using the fact that $\varphi = 0$ in $\Omega \setminus \Omega_1$, then if $w = u^{\epsilon}-\tilde{u}$ it follows from (\ref{NeumannCond}) that:
\begin{equation}
    \label{MainVariationalForm}
    \begin{array}{cc}
        \int_{\Omega} (\rho^{\epsilon} \partial_{tt}w, w) & + \big( A^{hk} \partial_{x_k} w, \partial_{x_h}w \big) = \int_{\Omega} (G_{tt}, w) - \int_{\Omega} (G_h^1,\partial_{x_h} w) - \int_{\Omega} ( G_h^2,\partial_{x_h} w) \\
        & \, + \int_{\Omega} (G_1^0, w) + (G_2^0, w) + (G_3^0, w) + \int_{\partial \Omega} (\sigma_{\epsilon}(w), w) \\
        & = \int_{\Omega} (G_{tt},w) - \int_{\Omega} (G_h^1, \partial_{x_h}w) - \int_{\Omega} (G_h^2, \partial_{x_h}w) \\
        & \, + \int_{\Omega} (G_1^0,w) + (G_2^0,w) + (G_3^0,w)
       % By continuity the below integrals 
       % & \, + \int_{\partial \Omega \setminus \Gamma_N} \big( (1-\varphi) A^{ij}\partial_{x_j}u^0, w \big) + \int_{\partial \Omega \setminus \Gamma_N} \big( (1-\varphi) A^{ij}_{hom}\partial_{x_j} u^0, w \big) 
    \end{array}
\end{equation}

Let us estimate the integrals in the right-hand side of the equality (\ref{MainVariationalForm}).
Note first from the construction of the cut function $\varphi$, we have that $\partial_{x_j} \varphi$ and $1-\varphi$ vanish on $\Omega \cap \{ \rho(x, \Gamma_D \} \geq \epsilon \}$ and moreover, $\vert \epsilon \nabla \varphi \vert \leq C$ for some constant $C > 0$ independent of $\epsilon > 0$.

\begin{lem}
\label{BoundLemma}
Let $\Omega'$ be a bounded domain with a smooth boundary segment $\Gamma' \subset \partial \Omega'$ and $B_{\delta}' = \{ \rho(\mathbf{x}, \Gamma') < \delta \}$ for $\delta > 0$. Then there exist $\delta_0 > 0$ such that for every $\delta \in (0, \delta_0)$ and every $v \in H^1(\Omega)$ we have:
\begin{equation*}
    \Vert v\Vert_{\mathbf{L}^2(B_{\delta}')} \lesssim \delta^{1/2} \Vert v \Vert_{\mathbf{H}^1(\Omega')}
\end{equation*}
where the constant associated is independent of $\delta$ and $v$.
\end{lem}
Therefore, using the Lemma (\ref{BoundLemma}) it follows from (\ref{Variables}) that:
\begin{equation}
    \label{G1Bound}
\left \vert \int_{\Omega} \big( G_h^1, \partial_{x_h} w\big) \right \vert + \left \vert \int_{\Omega} (G_1^0,w) \right \vert \lesssim \epsilon^{1/2} \Vert u^0 \Vert_{\mathbf{H}^3(\Omega)} \Vert w \Vert_{\mathbf{H}^1(\Omega)} 
\end{equation}
where the constant found in the bound is independent of $\epsilon > 0$.
Moreover, from again from (\ref{Variables}) it follows that:
\begin{equation}
    \label{G2Bound}
    \left \vert \int_{\Omega} (G^2_h, \partial_{x_h} w) \right \vert + \left \vert (G^0_2,w) \right \vert \lesssim \epsilon \Vert u^0 \Vert_{\mathbf{H}^3(\Omega)} \Vert w \Vert_{\mathbf{H}^1(\Omega)}
\end{equation}
where again, the constant found is independent of $\epsilon > 0$.
Now, let us define the expression:
\begin{equation}
    \label{J1Expression}
    \begin{array}{ccc}
        J_1 & = &\int_{\Omega} (G_3^0,w)\\ %+ \int_{\partial \Omega_1 \setminus \Gamma_D} \big( A^{ij}_{hom} (1-\varphi) \partial_{x_j}u^0 n_i,w) \\
        & = &-\int_{\Omega_1} (\partial_{x_h}(\varphi - 1) \alpha^{hk} \partial_{x_k}u^0,w) \\ %- \int_{\partial \Omega_1 \setminus \Gamma_D} (\varphi-1) \big( A^{ij}_{hom} \partial_{x_j} u^0 n_i,w) \\
        & = &-\int_{\partial \Omega_1} \big( \alpha^{hk} \partial_{x_k} u^0,w\big) \\% - \int_{\partial \Omega_1 \setminus \Gamma_D} \big( A^{ij}_{hom} \partial_{x_j} u^0 n_i, w\big) \\
        & &\, - \int_{\Omega_1} \big( (\varphi -1) \alpha^{hk} \partial_{x_k x_h} u^0,w\big) - \int_{\Omega_1} (\varphi -1) \big( \alpha^{hk} \partial_{x_k} u^0, \partial_{x_h}w \big)
    \end{array}
\end{equation}
\begin{rem}
Let us note that the integral over $\partial \Omega_1$ has normal $n$ exterior to $\partial \Omega_1$.
\end{rem}
It follows again, using the Lemma (\ref{BoundLemma}) on the last two integrals of (\ref{J1Expression}) the bound for them is given by:
\begin{equation*}
    \lesssim \epsilon^{1/2} \Vert u^0 \Vert_{\mathbf{H}^3(\Omega)} \Vert w \Vert_{\mathbf{H}^1(\Omega)}
\end{equation*}
It follows from the last equality (\ref{J1Expression}) that:
\begin{equation}
    \label{J1Bound}
    \vert J_1 \vert \leq \vert J_2 \vert + C \epsilon^{1/2} \Vert u^0 \Vert_{\mathbf{H}^3(\Omega)} \Vert w \Vert_{\mathbf{H}^1(\Omega)}
\end{equation}
where we have now:
\begin{equation}
    \label{J2Expression}
    J_2 = - \int_{\partial \Omega_1} \big( \alpha^{hk}(\frac{\mathbf{x}}{\epsilon}) n_h \partial_{x_k} u^0, w\big)
\end{equation}
Let us recall the following result:
\begin{lem}
Let the matrices $\gamma^{hk}(\mathbf{x})\in \big[L^{\infty}(\partial \Omega_1)\big]^{n\times n}$ be such that we have the uniform conditions
\begin{equation}
    \int_{\sigma_h^m} \gamma^{hk}(\mathbf{x}) = \mathbf{0}, \quad \underset{\partial \Omega_1}{sup} \vert \gamma^{hk} \vert \leq \gamma
\end{equation}
where $h,k \in \{1,\dots,n\}, m = \{1,\dots,l_h\}$ and $\gamma  > 0$ constant. Then for any vector valued function $u^0 \in \mathbf{H}^3(\Omega), \, w \in \mathbf{H}^1(\Omega)$ the inequality
\begin{equation}
    \label{GammaBound}
    \left \vert \int_{\partial \Omega_1} \big(\gamma_{hk} \partial_{x_k} u^0, w \big) \right \vert \lesssim \epsilon^{1/2} \gamma \Vert u^0 \Vert_{\mathbf{H}^3(\Omega)} \Vert w \Vert_{\mathbf{H}^1(\Omega)}
\end{equation}
independent of $\epsilon > 0$.
\end{lem}
Let us define then $\gamma^{hk} = \alpha^{hk}$. It follows that the conditions of the above Lemma are fulfilled, then by  (\ref{GammaBound}) we conclude that:
\begin{equation}
    \label{J2Bound}
    \vert J_2 \vert \lesssim \epsilon^{1/2} \Vert u^0 \Vert_{\mathbf{H}^3(\Omega)} \Vert w \Vert_{\mathbf{H}^1(\Omega)}
\end{equation}
It follows the desired result after using (\ref{G1Bound}),(\ref{G2Bound}), (\ref{J1Bound}), (\ref{J2Bound}), and the uniform bound for the expression with $G_{tt}$ since the regularity assumptions for $\mathbf{N}^q$.

\begin{rem}
Let us note from the above that we have the bound for each $t \in (0,T)$ given by:
\begin{equation}
    \label{TimeBound}
    \Vert u^{\epsilon} - u^0 - \epsilon \varphi \mathbf{N}^s\big( \frac{\mathbf{x}}{\epsilon} \big) \partial_{x_s} u^0 \Vert_{\mathbf{H}^1(\Omega, \Gamma_N)} \lesssim \epsilon^{1/2} \Vert \mathbf{F}\Vert_{L^{\infty}(0,T;\mathbf{L}^{2}(\Gamma_N))}
\end{equation}
\end{rem}
\section{Energy and Flow Estimations}
Let us define the energy operators $E_{\epsilon}$ and $E_{0}$ associated to the multiscale and homogenized problems defined in the form:
\begin{equation*}
    E_{\epsilon}(u^{\epsilon}) := \int_0^T \int_{\Omega} \frac{1}{2}u_i^{\epsilon}u_i^{\epsilon} + \int_0^T \int_{\Omega} \big( \partial_{x_j} u^{\epsilon}, A^{jk} \big( \frac{\mathbf{x}}{\epsilon}\big) \partial_{x_k} u^{\epsilon} \big)
\end{equation*}
and analogously:
\begin{equation*}
    E_0(u^0) := \int_0^T \int_{\Omega} \frac{1}{2}u_i^{0}u_i^{0} + \int_0^T \int_{\Omega} \big( \partial_{x_j} u^0, A^{jk} \big( \frac{\mathbf{x}}{\epsilon}\big) \partial_{x_k} u^0 \big)
\end{equation*}
We have the following result:
\begin{lem}
Assuming the hypothesis of the above theorem, we have the convergence of the energy operators, i.e., 
\begin{equation*}
    \vert E_{\epsilon} (u^{\epsilon}) - E_0 (u^0) \vert \lesssim \epsilon^{1/2} \Vert \mathbf{F} \Vert_{L^{\infty}(0,T; \mathbf{L}^{2}(\Gamma_N))} 
\end{equation*}
\end{lem}
\textbf{Idea for the proof} \\
Let us fix $t \in (0,T)$, it follows from the result (\ref{TimeBound}) the bounds for $u^{\epsilon}$ and $\partial_{x_i} u^{\epsilon}$ in the form:
\begin{equation*}
    u^{\epsilon} = u^0 + \epsilon \varphi \mathbf{N}^s\big( \frac{\mathbf{x}}{\epsilon} \big) \partial_{x_s} u^0 + r^{\epsilon}(\mathbf{x},t) 
\end{equation*}
where the remaining term is bounded for
\begin{equation*}
    \Vert r^{\epsilon}(\cdot, t) \Vert_{\mathbf{H}^1(\Omega; \Gamma_D)} \lesssim \epsilon^{1/2} \Vert \mathbf{F}\Vert_{L^{\infty}(0,T;\mathbf{L}^{2}(\Gamma_N))}
\end{equation*}
and for each $i \in \{1,2,3\}$:
\begin{equation*}
    \partial_{x_i} u^{\epsilon} = \partial_{x_i} u^0 + \epsilon \varphi \partial_{x_i} \mathbf{N}^s \big( \frac{\mathbf{x}}{\epsilon} \big) \partial_{x_s} u^0 + q^{\epsilon}_i(\mathbf{x},t)
\end{equation*}
where now, the remaining term satisfies 
\begin{equation*}
    \Vert q^{\epsilon}_i(\cdot, t) \Vert_{\mathbf{H}^1(\Omega, \Gamma_D)} \lesssim \epsilon^{1/2} \Vert \mathbf{F}\Vert_{L^{\infty}(0,T; \mathbf{L}^{2}(\Gamma_N))}
\end{equation*}
So that, using the definition of the energy operator, it follows that:
\begin{align*}
    E_{\epsilon}(u^{\epsilon}) &= \int_0^T \int_{\Omega} \frac{1}{2}(u^0 + \epsilon \varphi \mathbf{N}^s \big( \frac{\mathbf{x}}{\epsilon} \big) \partial_{x_s} u^0, u^0 + \epsilon \varphi \mathbf{N}^s \big( \frac{\mathbf{x}}{\epsilon} \big) \partial_{x_s} (u^0) \big) + R(r^{\epsilon}) \\
    & + \int_0^T \int_{\Omega} \big( \partial_{x_j} u^0 + \epsilon \varphi \partial_{x_j} \mathbf{N}^s \big( \frac{\mathbf{x}}{\epsilon} \big) \partial_{x_s} u^0, A^{jk} \big(\frac{\mathbf{x}}{\epsilon} \big) \big[\partial_{x_k} u^0 + \epsilon \varphi \partial_{x_k} \mathbf{N}^s \big( \frac{\mathbf{x}}{\epsilon}\big) \partial_{x_s} u^0 \big] \big) + Q(q^{\epsilon})
\end{align*}
where the remaining integral terms can be bounded by
\begin{equation*}
    \vert R(r^{\epsilon}) \vert \lesssim \epsilon^{1/2} \Vert \mathbf{F}\Vert_{L^{\infty}(0,T;\mathbf{L}^{2}(\Gamma_N))} 
\end{equation*}
and moreover
\begin{equation*}
    \vert Q(q^{\epsilon} \vert \lesssim \epsilon^{1/2} \Vert \mathbf{F}\Vert_{L^{\infty}(0,T;\mathbf{L}^{2}(\Gamma_N))}
\end{equation*}
since the functions $u^0, \partial_{x_k}u^0, \mathbf{N}^s, \partial_{x_k} \mathbf{N}^s$ are bounded.


\section{Objective}
ADD AS A FOOTNOTE THE REFERENCE INSPIRATION PAPER!
We'll give estimations for the effective coefficients, and also obtain a sort of continuity property with respect to $p$ being associated to the porosity.

The idea is to identify the elasticity tensor $\mathbf{C}(\mathbf{y}, p)$ in a domain $\mathbf{Y}$ with parameter $p \in [0,1]$ related to the cell domain, an the porosity respectively.

\section{Definition and Estimates}
\begin{defn}
Let us define the set of linear operators 
\begin{equation*}
    \mathbf{T}([0,1]\times \mathbf{Y}) := \big \{ \mathbf{C}(\mathbf{y}) \in L^{\infty}([0,1]; \text{lin}(\mathbb{S}^3)\, : \mathbf{C}(\cdot, p)^* = \mathbf{C}(\cdot, p) \big \}
\end{equation*}
where we are using the notation of $\mathbb{S}^n$ as the space of $n\times n$ symmetric matrices, being $n=2,3$.
\end{defn}
\begin{rem}
Note that, the linear elastic tensors $\mathbf{C} = C_{ijkl}$ belong to $\mathbf{T}([0,1]\times \mathbf{Y})$. In particular, the symmetry of the tensors expressed in Voigt notation as $C_{IJ}=C_{JI}$ is expressed by the condition of being an adjoint operator, i.e. symmetric since we are identifying the the linear operator of $\mathbb{S}^3$ by the a four-dimensional array.
\end{rem}
With the above definition we can then define the space of bounded tensors with parameters $(\alpha,\beta) \in \mathbb{R_+}^2$ as a subset of $\mathbf{T}([0,1]\times \mathbf{Y})$ with the following conditions:
Let $\mathbf{C} \in \mathbf{T}([0,1]\times \mathbf{Y})$ and consider the hypothesis:
\begin{enumerate}
    \item[(H1)] If $\alpha \xi \cdot \xi \leq \mathbf{C}(\mathbf{y},p)  \xi\cdot\xi\, \text{a.e.} \mathbf{y} \in \mathbf{Y}, \forall p \in [0,1]$.
    \item[(H2)] If $\vert \mathbf{C}(\mathbf{y},p) \cdot \xi \vert \leq \beta \vert \xi \vert^2 \, \text{a.e.}\mathbf{y} \in \mathbf{Y}, \forall p \in [0,1]$
    \item[(H3)] If $\mathbf{C}(\cdot,p))^T = \mathbf{C}(\cdot, p) \,\forall p \in [0,1]$
\end{enumerate}
So that we can define the space of elastic tensors:
\begin{defn}
We say that $\mathbf{C} \in \mathcal{T}(\alpha, \beta, [0,1]\times \mathbf{Y})$
if $\mathbf{C}$ satisfies $(H1)-(H2)-(H3)$.
\end{defn}
\begin{rem}
In the two-scale elastodynamic model formulation, the linear elastic tensor can be considered by
\begin{equation*}
    \mathbf{C}^{\epsilon}(\mathbf{x},p) = \mathbf{C}(\frac{\mathbf{x}}{\epsilon},p)
\end{equation*} being $\mathbf{x}\in \Omega$ the macroscopic domain with the natural condition $\mathbf{C} \in \mathcal{T}(\alpha, \beta, \mathbf{Y}\times [0,1])$ for each $\epsilon >0$. Recall also that, the $\epsilon$ parameter indicates the relation of micro-to-macro structure scales.
\end{rem}
By using the two-scale homogenization method, we can obtain an \textit{homogenized} (or effective) equation governing the macroscopic elastodynamic behavior with effective coefficients given at porosity $p \in [0,1]$ by:
\begin{equation*}
    C^0_{ijrs}(p) = \frac{1}{\vert \mathbf{Y}\vert} \int\limits_{\mathbf{Y}} C_{ijkl}(\mathbf{y},p) \, dy + \frac{1}{\vert \mathbf{Y}\vert} \int\limits_{\mathbf{Y}} C_{ijkl}(\mathbf{y},p) \mathbf{e}_{kl,y}( N^{rs})\,dy
\end{equation*}
for each $ i,j,r,s \in \{1,2,3\}$, where the cell vector functions $(N^{rs})_{rs}$ are defined as the unique solution each of the cell problems defined for each $i \in \{1,2,3\}$ by:
\begin{equation}
    \label{eq:cell}
    -\partial_{y_j} \big[ C_{ijkl}(\mathbf{y},p) \mathbf{e}_{kl}(N^{rs}) \big] = \partial_{y_j} \big[ C_{ijrs}(\mathbf{y},p) \big] 
\end{equation}
with the condition $\langle N^{rs} \rangle_{\mathbf{Y}} = 0$ for each $r,s \in \{1,2,3\}$.
So, we find solutions $(N^{rs})(\cdot,p)$ to the cell problem above in the space
\begin{equation*}
    H^1_{\#, 0} (\mathbf{Y}) := \big \{ N \in \big[ H^1(\mathbf{Y}) \big]^n \, : \, N \text{ being } \mathbf{Y}-\text{periodic}; \, \langle N \rangle_{\mathbf{Y}}=0 \big \}
\end{equation*}
\subsection{Variational Formulations}
Seeking solution to (\ref{eq:cell}) can be seen in the variational for each $r,s \in \{1,2,3\}$ as:
\begin{equation}
    \label{eq:cell_variational}
    \left \{
    \begin{array}{cc}
        \text{Find a function } N^{rs} \in H^1_{\#,0}(\mathbf{Y}) \text{ such that: } \forall v \in H^1_{\#, 0}(\mathbf{Y})&\\
        \int\limits_{\mathbf{Y}} C_{ijkl}(\mathbf{y},p)\mathbf{e}_{kl,y} \partial_{y_j}(v_i)\,dy = -\int\limits_{\mathbf{Y}} C_{ijrs}(\mathbf{y},p) \partial_{y_j}(v_i)\,dy & 
    \end{array}
    \right.
\end{equation}

\begin{rem}
In (\ref{eq:cell_variational}), the boundary term missing vanishes by adding a symmetry condition over the cell-boundaries, which we assume in all that follows.
\end{rem}
Note the variational formulation (\ref{eq:cell_variational}) can be rewritten by the symmetry of the operator $\mathbf{C}(\cdot,p)$ in the form:
\begin{equation}
    \label{eq:cell_symmetric}
    \left \{
    \begin{array}{cc}
        \text{Find a function } N^{rs} \in H^1_{\#,0}(\mathbf{Y}) \text{ such that: } \forall v \in H^1_{\#, 0}(\mathbf{Y})&\\
        \int\limits_{\mathbf{Y}} C_{ijkl}(\mathbf{y},p)\mathbf{e}_{kl,y} \mathbf{e}_{kl,y}(v)\,dy = -\int\limits_{\mathbf{Y}} C_{ijrs}(\mathbf{y},p) \mathbf{e}_{ij,y}(v)\,dy & 
    \end{array}
    \right.
\end{equation}
Let us now define the following useful notation for the contraction of the last two indices of a tensor:
\begin{defn}
Let us consider $\mathbf{a} = (a_{ij})_{ij}$ and $\mathbf{b} = (b_{ij})_{ij}$ matrices, and consider $\mathbf{A}=(A_{ijkl})_{ijkl}$ a element of $\mathbf{T}([0,1]\times \mathbf{Y})$ identified as a multidimensional array. We define the contraction of two indices by
\begin{equation*}
    \mathbf{a}:\mathbf{b} := a_{ij}b_{ij}
\end{equation*}
and naturally we extend the definition to three elements in the form:
\begin{equation*}
    \mathbf{A}:\mathbf{a}:\mathbf{b} := A_{ijkl}a_{kl}b_{ij}
\end{equation*}
\end{defn}
\begin{rem}
In particular, if we assume that $\mathbf{A}$ satisfies $(H3)$ then if follows that:
\begin{equation}
    \mathbf{A}: \mathbf{a}:\mathbf{b}= \mathbf{A}:\mathbf{b}:\mathbf{a}
\end{equation}
\end{rem}

%%%%%%%%%%%%%%%%%%%%%%%%%5
\subsection{Rewritten Coefficients}
Let us define the base of $\mathbb{S}^3$ by $(m_{ij})_{ij}$. Observe that the homogenized coefficient (w.l.o.g $\vert \mathbf{Y} \vert = 1$) can be rewritten in the following form:
\begin{equation}
    \label{eq:effective_coef}
    \begin{array}{ccc}
        C_{ijrs}(p) &=& \int\limits_{\mathbf{Y}} \mathbf{C}(\mathbf{y},p):m_{rs}:m_{ij} + \int\limits_{\mathbf{Y}} \mathbf{C}(\mathbf{y},p):\mathbf{e}(N^{rs}):m_{ij} \\
         &=&\int\limits_{\mathbf{Y}} \mathbf{C}(\mathbf{y},p):\big(m_{rs} + \mathbf{e}(N^{rs})\big):m_{ij}
    \end{array}
\end{equation}

In particular, using (\ref{eq:cell_symmetric}) and taking $v := N^{ij} \in H^1_{\#,0}(\mathbf{Y})$ we obtain the following equality:
\begin{equation}
    \label{eq:cell_Nij}
    \int\limits_{\mathbf{y}}\mathbf{C}(\mathbf{y},p):\mathbf{e}(N^{rs}): \mathbf{e}(N^{ij}) \, dy = - \int\limits_{\mathbf{y}} \mathbf{C}(\mathbf{y},p):\mathbf{e}(N^{ij}):m_{rs}\, dy
\end{equation}
So, by using the above equality (\ref{eq:cell_Nij}) with our expression (\ref{eq:effective_coef}) for the effective coefficients, it follows:
\begin{equation}
    \label{eq:effective_coef_symmetric}
    C_{ijkl}^0(p) = \int\limits_{\mathbf{Y}} \mathbf{C}(\mathbf{y},p):(m_{rs}+\mathbf{e}(N^{rs})):(m_{ij}+\mathbf{e}(N^{ij}))
\end{equation}
%%%%%%%%%%%%%%
\subsection{About the Derivative}
Let us differentiate (\ref{eq:effective_coef_symmetric}) with respecto to the parameter $p$. It follows then:
\begin{equation*}
    \partial_{p} \big( C_{ijkl}^0 (p) \big) = \int\limits_{\mathbf{Y}} \partial_{p}\big( \mathbf{C}(\mathbf{y},p) \big) : (m_{rs}+\mathbf{e}(N^{rs}) :(m_{ij}+\mathbf{e}(N^{ij})) + 2C_{ijrs}^0(p)
\end{equation*}
since the elements given by the integration by parts using (\ref{eq:cell_Nij}) vanish CHECK THIS RESULT!!

By using (\ref{eq:cell_symmetric}), the coercivity of $\mathbf{C}(\cdot, p)$ and H\"{o}lder inequality, it follows that:
\begin{equation*}
    \kappa \int\limits_{\mathbf{y}} \mathbf{e}(N^{rs}) : \mathbf{e}(v) \, dy \leq \Vert C(\cdot, p) :m_{rs}\Vert_{M(\mathbf{Y})} \Vert \mathbf{e}(v)\Vert_{M(\mathbf{Y})}
\end{equation*}
where we denote by $M(\mathbf{Y}):=[L^2 (\mathbf{Y})]^{n\times n}$, with dot product defined by $:$, i.e., the contraction. \\
Even more, by a duality argument we can bound $\mathbf{e}(N^{rs})$ in the form:
\begin{equation}
    \label{eq:bound_Nrs}
    \Vert \mathbf{e}(N^{rs}) \Vert_{M(\mathbf{Y})} \leq \kappa^{-1}\Vert C(\cdot, p) :m_{rs}\Vert_{M(\mathbf{Y})}, \quad \forall r,s =1,2,3
\end{equation}
and then, by the $beta$-boundness of $\mathbf{C}$ it follows in particular from (\ref{eq:bound_Nrs}):
\begin{equation*}
    \Vert \mathbf{e}(N^{rs}) \Vert_{M(\mathbb{Y}} \leq \frac{\beta}{\kappa}
\end{equation*}


\subsection{About the Continuity}
For the continuity of the effective coefficients, let us take $p,q \in [0,1]$ (porosity levels). First, let us show a usefull estimation of $N^{rs}(p)-N^{rs}(q)$ for each $r,s \in \{1,2,3\}$. Using (\ref{eq:cell_symmetric}) it's possible to obtain that:
\begin{equation}
    \label{eq:diff_Nrs}
    \begin{array}{ccc}
        \int\limits_{\mathbf{Y}} \mathbf{C}(\mathbf{y},p):\mathbf{e}\big( N^{rs}(p)-N^{rs}(q) \big) :\mathbf{e}(v) & = & -\int\limits_{\mathbf{Y}} \mathbf{C}(p)-\mathbf{C}(q) : m_{rs}:\mathbf{e}(v) \\
        &\,&- \int\limits_{\mathbf{Y}}\mathbf{C}(p)-\mathbf{C}(q):\mathbf{e}(N^{rs}(q)):\mathbf{e}(v)
    \end{array}
\end{equation}
Then, using (\ref{eq:diff_Nrs}) it follows the representation $\forall v \in H^1_{\#,0}(\mathbf{Y})$
\begin{equation}
    \label{eq:diff_Nrs_full}
    \int\limits_{\mathbf{Y}} \mathbf{C}(p):\mathbf{e}\big(N^{rs}(p)-N^{rs}(q)\big):\mathbf{e}(v) = -\int\limits_{\mathbf{Y}} \mathbf{C}(p)-\mathbf{C}(q):m_{rs}+\mathbf{e}(N^{rs}(q)):\mathbf{e}(v)
\end{equation}
In particular, from (\ref{eq:diff_Nrs_full}) by a duality argument we obtain
\begin{equation*}
    \Vert \mathbf{C}(p):\mathbf{e}\big(N^{rs}(p)-N^{rs}(q)\big) \Vert_{M(\mathbf{Y}} \leq \mathbf{C}(p)-\mathbf{C}(q):m_{rs}+\mathbf{e}(N^{rs}(q))\Vert_{M(\mathbf{Y}}
\end{equation*}
from which after taking H\"{o}lder inequality we have:
\begin{equation}
    \label{eq:ineq_diff_C}
    \Vert \mathbf{C}(p):\mathbf{e}\big(N^{rs}(p)-N^{rs}(q)\big) \Vert_{M(\mathbf{Y}} \leq \Vert \mathbf{C}(p)-\mathbf{C}(q) \Vert_{M(\mathbf{Y}} \Vert m_{rs}+\mathbf{e}(N^{rs}) \Vert_{M(\mathbf{Y}}
\end{equation}
\begin{rem}
Let us note that in the above inequalities follows using that $M(\mathbf{Y}) = M(\mathbf{Y})^*$, since $M(\mathbf{Y})$ can can be identified as a $n\times n$ cross product of a Hilbert space.
\end{rem}
Let us suppose then a continuity condition for the operators $\mathbf{C}$ in the form:
\begin{equation*}
    \Vert \mathbf{C}(p)-\mathbf{C}(q) \Vert_{M} \lesssim \vert p-q\vert^{\alpha}, \quad \alpha \in \mathbb{R}
\end{equation*}
So that, we can obtain from (\ref{eq:ineq_diff_C}) the following estimate:
\begin{equation*}
    \Vert \mathbf{C}(p):\mathbf{e}\big(N^{rs}(p)-N^{rs}(q) \big) \Vert_{M(\mathbf{Y}} \lesssim \vert p-q\vert^{\alpha} (1+ \Vert \mathbf{C}\Vert_{M(\mathbf{Y})} \kappa^{-1})
\end{equation*}

